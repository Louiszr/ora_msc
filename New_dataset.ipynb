{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New dataset for abundance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class definition of a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetabolomicsSample:\n",
    "    def __init__(self, sample_id, liver_fat, infusion, serum, patient_id):\n",
    "        '''\n",
    "        id, liver fat, insulin infusion, serum type, patient, compound:abundance\n",
    "        '''\n",
    "        self.sample_id = sample_id\n",
    "        self.liver_fat = liver_fat\n",
    "        self.infusion = infusion\n",
    "        self.serum = serum\n",
    "        self.patient_id = patient_id\n",
    "        self._data = dict()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.sample_id\n",
    "    \n",
    "    def getSampleInfo(self):\n",
    "        print(self.sample_id)\n",
    "        print(\"Liver fat(percentage):\", self.liver_fat)\n",
    "        print(\"Insulin infusion: \" + self.infusion)\n",
    "        print(\"Serum type: \" + self.serum)\n",
    "        print(\"Patient id: \" + self.patient_id)\n",
    "    \n",
    "    def addOmicsData(self, metabolite_id, value):\n",
    "        '''\n",
    "        Find the existing entry of the metabolite in the data dictionary, add value to the existing entry\n",
    "        If no existing entry can be found, create an entry for the metabolite\n",
    "        Values have to be in float!!\n",
    "        '''\n",
    "        if not isinstance(value, float):\n",
    "            print(\"Data values must be floats\")\n",
    "            return 0\n",
    "        self._data[metabolite_id] = self._data.get(metabolite_id, 0) + value\n",
    "        \n",
    "    def getOmicsData(self):\n",
    "        return self._data\n",
    "    \n",
    "    def clearOmicsData(self):\n",
    "        self._data = dict()\n",
    "        \n",
    "    def avgOmicsData(self, replicate):\n",
    "        '''\n",
    "        Average the omics data from two replicates\n",
    "        Return with a new object that has the average omics data\n",
    "        ***If one replicate has 0 for a metabolite, the average will be 0\n",
    "        \n",
    "        Could potentially add an attribute that states whether a study has been averaged or not\n",
    "        '''\n",
    "        if not isinstance(replicate, MetabolomicsSample):\n",
    "            print(\"Replicate must be a MetabolomicsSample sample\")\n",
    "            return 0\n",
    "        elif (replicate.liver_fat != self.liver_fat or \n",
    "              replicate.infusion != self.infusion or \n",
    "              replicate.serum != self.serum or \n",
    "              replicate.patient_id != self.patient_id):\n",
    "            print(\"Study info do not match\")\n",
    "            return 0\n",
    "        mean_study = MetabolomicsSample(self.sample_id, self.liver_fat, \n",
    "                                        self.infusion, self.serum, self.patient_id)\n",
    "        for metabolite in self.getOmicsData():\n",
    "            if self.getOmicsData()[metabolite] == 0 or replicate.getOmicsData()[metabolite] == 0:\n",
    "                avg_abundance = 0.0\n",
    "            else:\n",
    "                avg_abundance = (self.getOmicsData()[metabolite] + replicate.getOmicsData()[metabolite]) / 2\n",
    "            mean_study.addOmicsData(metabolite, avg_abundance)\n",
    "        return mean_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average Jaccard coefficient\n",
    "def mean_jaccard_coeff(in_list):\n",
    "    all_jaccard_coeff = []\n",
    "    for combination in itertools.combinations(in_list, 2):\n",
    "        (pathway1, pathway2) = combination\n",
    "        #print(pathway1, pathway2)\n",
    "        intersect_size = len(pathway1 & pathway2)\n",
    "        union_size = len(pathway1 | pathway2)\n",
    "        jaccard_coeff = intersect_size / union_size\n",
    "        all_jaccard_coeff.append(jaccard_coeff)\n",
    "    all_jaccard_coeff = np.mean(all_jaccard_coeff)\n",
    "    return all_jaccard_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion: Chebi to KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bioservices import KEGG, ChEBI\n",
    "import ora_msc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ch = ChEBI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_chebi_kegg(chebi_id, chebi_instance):\n",
    "    '''\n",
    "    converting chebi ids to kegg ids\n",
    "    if the chebi entry does not have database links\n",
    "    return the ascii name of that entry\n",
    "    '''\n",
    "    res = chebi_instance.getCompleteEntity(chebi_id)\n",
    "    try:\n",
    "        for link in res.DatabaseLinks:\n",
    "            if link.type == 'KEGG COMPOUND accession':\n",
    "                kegg_id = link.data\n",
    "                return kegg_id\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return res.chebiAsciiName\n",
    "\n",
    "def avg_replicates_study(repstudies):\n",
    "    '''\n",
    "    Only works when there are exactly two replicates\n",
    "    Must sort the input list by patient id first!!!\n",
    "    '''\n",
    "    avg_studies = []\n",
    "    for i in range(0, len(repstudies), 2):\n",
    "        study_rep1 = repstudies[i]\n",
    "        study_rep2 = repstudies[i+1]\n",
    "        study_avg = study_rep1.avgOmicsData(study_rep2)\n",
    "        avg_studies.append(study_avg)\n",
    "    return avg_studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTBLS298\n",
    "242 Unique Chebi IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = '/data/zx2313/MTBLS298/' # The location of the maf file\n",
    "#directory = '/home/zxu/Documents/mscbioinfo/data/MTBLS298/'\n",
    "maf = directory + 'm_catheterization_study_metabolite_profiling_mass_spectrometry_v2_maf.tsv'\n",
    "sample_info = directory + 's_Catheterization study.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialise metabolomics samples\n",
    "met_studies = []\n",
    "with open(sample_info, 'r') as fh:\n",
    "    for line in fh.readlines()[1:]:\n",
    "        fields = line.rstrip().split('\\t')\n",
    "        sample_id = fields[8][1:-1]\n",
    "        liver_fat = int(fields[9][1:-1])\n",
    "        infusion = fields[16][1:-1]\n",
    "        serum = fields[19][1:-1]\n",
    "        patient_id = fields[22][1:-1]\n",
    "        met_studies.append(MetabolomicsSample(sample_id, liver_fat, infusion, serum, patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(maf, 'r') as fh:\n",
    "    study_indices = []\n",
    "    lines = fh.readlines()\n",
    "    for line in lines[0:1]:\n",
    "        fields = line.rstrip().split('\\t')\n",
    "        #print(fields[0], fields[4], fields[11], fields[14], fields[16], fields[17], fields[21:81])# 0 4 11 14 16 17 21-80\n",
    "        for field in fields[21:81]:\n",
    "            sample_id = field[1:-5]\n",
    "            for index in range(0, len(met_studies)):\n",
    "                study = met_studies[index]\n",
    "                if sample_id == study.sample_id:\n",
    "                    study_indices.append(index)\n",
    "                    \n",
    "    for line in lines[1:]:\n",
    "        fields = line.rstrip().split('\\t')\n",
    "        database_id = fields[0][1:-1]\n",
    "        if not database_id.startswith('CHEBI'):\n",
    "            continue # If the metabolite is not chebi, go to the next line\n",
    "        else:\n",
    "            converted_id = conv_chebi_kegg(database_id, ch)\n",
    "        if not (converted_id.startswith('C') and len(converted_id) == 6):\n",
    "            continue # If the converted id is not kegg, go to the next line\n",
    "        for index in range(21, 81): #fields[21:81]:\n",
    "            study_index = study_indices[index - 21]\n",
    "            omics_value = float(fields[index][1:-1])\n",
    "            met_studies[study_index].addOmicsData(converted_id, omics_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "met_studies.sort(key = lambda x: x.patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basal_studies = []\n",
    "insulin_studies = []\n",
    "for study in met_studies:\n",
    "    if study.infusion == 'Basal':\n",
    "        basal_studies.append(study)\n",
    "    elif study.infusion == 'Insulin':\n",
    "        insulin_studies.append(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_basal_studies = avg_replicates_study(basal_studies)\n",
    "avg_insulin_studies = avg_replicates_study(insulin_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_basal_studies = avg_basal_studies[:8] + avg_basal_studies[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_insulin_studies = avg_insulin_studies[:5] + avg_insulin_studies[6:7] + avg_insulin_studies[8:9] + avg_insulin_studies[10:11] + avg_insulin_studies[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for study in avg_basal_studies:\n",
    "    print(study.patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for study in avg_insulin_studies:\n",
    "    print(study.patient_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-tests\n",
    "- Conditions: basal vs insulin\n",
    "- samples from the same patient and serum were paired together (12 vs 12)\n",
    "- If a zero abundance is present for one metabolite, its abundance in the related sample will be also removed and excluded from the paired t-tests\n",
    "- CONCERN: Small sample size (< 8) for Wilcoxon tests??\n",
    "- before multiple-testing corrections: 11 DE metabolites\n",
    "- after multiple-testing corrections: 1 DE metabolite\n",
    "- 22/08: Multiple-testing corrections not important, so therefore they are removed\n",
    "- 28/08: Changing p-val cutoff to get more DE metabolites. More DE metabolites did not improve pathway p-vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# FDR\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# go through one metabolite in all samples\n",
    "# do the same thing with the other condition\n",
    "# if the paired t-test is significant, add the metabolite to the DE list\n",
    "# if any zero is present in one sample, remove the related data in the other condition\n",
    "p_cutoff = 1\n",
    "de_metabolites = []\n",
    "all_metabolites = list(avg_basal_studies[0].getOmicsData().keys())\n",
    "for metabolite in all_metabolites:\n",
    "    b_study_paired_abun = []\n",
    "    i_study_paired_abun = []\n",
    "    for index in range(0, len(avg_basal_studies)):\n",
    "        b_study = avg_basal_studies[index]\n",
    "        i_study = avg_insulin_studies[index]\n",
    "        if b_study.getOmicsData()[metabolite] != 0.0 and i_study.getOmicsData()[metabolite] != 0.0:\n",
    "            # if neither of the abundance is zero, add the data points to the paired list\n",
    "            b_study_paired_abun.append(b_study.getOmicsData()[metabolite])\n",
    "            i_study_paired_abun.append(i_study.getOmicsData()[metabolite])\n",
    "    #print(len(b_study_paired_abun), len(i_study_paired_abun))\n",
    "    if len(b_study_paired_abun) == 1 or len(i_study_paired_abun) == 1: # Skip this met if DOF too small\n",
    "        continue\n",
    "    p_val = scipy.stats.ttest_rel(b_study_paired_abun, i_study_paired_abun)[1]\n",
    "    if p_val < p_cutoff:\n",
    "        #print(metabolite, p_val)\n",
    "        de_metabolites.append(metabolite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "de_metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate DE metabolites\n",
    "- 1: Pick a pathway from dataset_paths\n",
    "- 2: Pick a proportion of its metabolites\n",
    "- 3: Make them DE\n",
    "- 4: ORA\n",
    "- 5: Delete metabolites based on abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kegg = KEGG()\n",
    "kegg.organism = 'hsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsa_pathways = kegg.pathwayIds\n",
    "pathway_2_compounds = dict()\n",
    "for pathway in hsa_pathways:\n",
    "    parsed_output = kegg.parse(kegg.get(pathway)) # parsed_ouput has lots of information about the pathway\n",
    "    try:\n",
    "        compounds = set(parsed_output['COMPOUND'].keys())\n",
    "        pathway_2_compounds[pathway] = compounds\n",
    "    except KeyError: # Some pathways do not have defined compounds\n",
    "        #name = parsed_output['NAME']\n",
    "        #print(pathway, name)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulating DE metabolites\n",
    "def simulateDEmet(dataset_paths, sigpaths_num,\n",
    "                  pathway_2_compounds, background_met,\n",
    "                  verbose=False):\n",
    "    augmented_paths = []\n",
    "    for i in range(0, sigpaths_num): # Select significant pathways\n",
    "        random.shuffle(dataset_paths)\n",
    "        augmented_paths.append(dataset_paths[0])\n",
    "        if verbose:\n",
    "            print(dataset_paths[0])\n",
    "    de_metabolites = set()\n",
    "    for pathway in augmented_paths: # Make DE metabolites\n",
    "        pathway_met = list(pathway_2_compounds[pathway] & background_met) # background mets which existed in KEGG pathway DB\n",
    "        trim = int(len(pathway_met) * 0.6) + 1\n",
    "        random.shuffle(pathway_met)\n",
    "        pathway_met = pathway_met[:trim]\n",
    "        de_metabolites = de_metabolites.union(pathway_met)\n",
    "    if verbose:\n",
    "        print(de_metabolites)\n",
    "    return de_metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065572248412331488"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_jaccard_coeff(new_p2c.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_p2c = dict()\n",
    "for pathway in dataset_paths:\n",
    "    detectable_metabolite = pathway_2_compounds[pathway] & background_met\n",
    "    new_p2c[pathway] = detectable_metabolite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_paths = ora_msc.oras_allpaths(background_met, hsa_pathways, background_met, pathway_2_compounds, True, False, 0, [])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:hsa04540\n",
      "path:hsa05120\n",
      "{'C03758', 'C00086'}\n"
     ]
    }
   ],
   "source": [
    "de_metabolites = simulateDEmet(dataset_paths, 2, pathway_2_compounds, background_met, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metabolite:abundance\n",
    "- all zeros were excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mets = list(met_studies[0].getOmicsData().keys())\n",
    "#print(mets)\n",
    "met_abundance = dict()\n",
    "for study in met_studies:\n",
    "    for metabolite in mets:\n",
    "        #print(met_abundance)\n",
    "        #print(metabolite)\n",
    "        study_abundance = study.getOmicsData()[metabolite]\n",
    "        #print(study_abundance)\n",
    "        if study_abundance == 0:\n",
    "            continue\n",
    "        #print(study_abundance)\n",
    "        try:\n",
    "            met_abundance[metabolite].append(study_abundance)\n",
    "        except KeyError:\n",
    "            met_abundance[metabolite] = [study_abundance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change all abundance to a mean abundance\n",
    "for metabolite in met_abundance:\n",
    "    mean_abundance = np.mean(met_abundance[metabolite])\n",
    "    met_abundance[metabolite] = mean_abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort metabolites based on their average abundance\n",
    "sorted_met = sorted(met_abundance.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "background_met = set(met_abundance.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORA\n",
    "- No significant pathways with the 11 DE metabolites input\n",
    "- P-vals became worse as the DE metabolite cutoff increased..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#background_met = set(avg_basal_studies[0].getOmicsData().keys())\n",
    "background_met = set(background_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(background_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(set(de_metabolites), hsa_pathways, background_met, pathway_2_compounds, True, False, 0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path in dict(zip(path_ids, path_pvals)):\n",
    "    if dict(zip(path_ids, path_pvals))[path] < 0.05:\n",
    "        print(path, dict(zip(path_ids, path_pvals))[path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DE metabolites: {'C00086', 'C00037', 'C00429', 'C00187'}\n",
      "# P-val cutoff: 0.05\n",
      "# Significant pathways: 3\n",
      "removed\ttp\tfp\ttn\tfn\tnonsig\tlowmet\ttested\taccu\trecall\tprecision\n",
      "0.0655722484123\n",
      "0\t3\t0\t29\t0\t0\t0\t32\t1.00\t1.00\t1.00\n",
      "0.0707967738561\n",
      "10\t3\t0\t29\t0\t0\t0\t32\t1.00\t1.00\t1.00\n",
      "0.0759410917271\n",
      "20\t3\t0\t29\t0\t0\t0\t32\t1.00\t1.00\t1.00\n",
      "0.0790006363964\n",
      "30\t2\t0\t29\t1\t1\t0\t30\t0.97\t0.67\t1.00\n",
      "0.0819199377309\n",
      "40\t2\t0\t29\t1\t1\t0\t30\t0.97\t0.67\t1.00\n",
      "0.0887206261752\n",
      "50\t2\t0\t29\t1\t1\t0\t30\t0.97\t0.67\t1.00\n",
      "0.0991322169894\n",
      "60\t2\t0\t29\t1\t1\t0\t30\t0.97\t0.67\t1.00\n",
      "0.139195738518\n",
      "70\t0\t0\t29\t3\t3\t0\t30\t0.91\t0.00\tnan\n",
      "0.13567251462\n",
      "80\t0\t0\t29\t3\t3\t0\t17\t0.91\t0.00\tnan\n",
      "0.157135945815\n",
      "90\t0\t0\t29\t3\t3\t0\t17\t0.91\t0.00\tnan\n"
     ]
    }
   ],
   "source": [
    "# ORA with abundance cutoffs\n",
    "#nums_removed_metabolites = [0, 25, 50, 75]\n",
    "PVAL_CUTOFF = 0.05\n",
    "de_metabolites = simulateDEmet(dataset_paths, 2, pathway_2_compounds, background_met)\n",
    "(path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(set(de_metabolites), hsa_pathways, background_met,\n",
    "                                                           pathway_2_compounds, True, False, 0, [])\n",
    "correct_pathway_hits = set()\n",
    "for path in dict(zip(path_ids, path_pvals)):\n",
    "    if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "        correct_pathway_hits.add(path)\n",
    "\n",
    "all_tested_paths = set(path_ids) # Store for the calculation of negatives\n",
    "\n",
    "print('# DE metabolites:', de_metabolites)\n",
    "print('# P-val cutoff:', PVAL_CUTOFF)\n",
    "print('# Significant pathways:', str(len(correct_pathway_hits)))\n",
    "print('removed', 'tp', 'fp', 'tn', 'fn', 'nonsig', 'lowmet', 'tested', 'accu', 'recall', 'precision', sep='\\t')\n",
    "\n",
    "for rem in range(0, 100, 10):\n",
    "    new_de_mets = set()\n",
    "    new_background = set()\n",
    "    removed_mets = []\n",
    "    new_pathway_hits = set()\n",
    "    new_pathway_nonsig = set()\n",
    "    new_pathway_negs = set()\n",
    "    # Select removed metabolites and remove them from DE and background\n",
    "    for item in sorted_met[:rem]:\n",
    "        metabolite = item[0]\n",
    "        removed_mets.append(metabolite)\n",
    "    for metabolite in de_metabolites:\n",
    "        if metabolite not in removed_mets:\n",
    "            new_de_mets.add(metabolite)\n",
    "    for metabolite in background_met:\n",
    "        if metabolite not in removed_mets:\n",
    "            new_background.add(metabolite)\n",
    "    # Calculate average jaccard coefficient        \n",
    "    new_p2c = dict()\n",
    "    for pathway in dataset_paths:\n",
    "        detectable_metabolite = pathway_2_compounds[pathway] & new_background\n",
    "        if len(detectable_metabolite) == 0:\n",
    "            continue\n",
    "        new_p2c[pathway] = detectable_metabolite\n",
    "    print(mean_jaccard_coeff(new_p2c.values()))\n",
    "    # ORA\n",
    "    (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(new_de_mets, hsa_pathways, new_background,\n",
    "                                                               pathway_2_compounds, True, False, 0, [])\n",
    "    #if len(path_ids) == 0:\n",
    "    #    pass\n",
    "    # Report results\n",
    "    for path in dict(zip(path_ids, path_pvals)):\n",
    "        if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "            new_pathway_hits.add(path)\n",
    "        else:\n",
    "            new_pathway_nonsig.add(path)\n",
    "    \n",
    "    new_pathway_negs = all_tested_paths.difference(new_pathway_hits)\n",
    "    \n",
    "    tp = len(correct_pathway_hits & new_pathway_hits)\n",
    "    fp = len(new_pathway_hits.difference(correct_pathway_hits))\n",
    "    fn = len(new_pathway_negs & correct_pathway_hits)\n",
    "    tn = len(new_pathway_negs.difference(correct_pathway_hits))\n",
    "    fn_nonsig = len(new_pathway_nonsig & correct_pathway_hits)\n",
    "    fn_lowmet = fn - fn_nonsig\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    #recall = tp / (tp + fn)\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = np.NaN\n",
    "    try:\n",
    "        precision = tp /(tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = np.NaN\n",
    "    #print(len(path_ids))\n",
    "    print(rem, tp, fp, tn, fn, fn_nonsig, fn_lowmet, len(path_ids),\n",
    "          \"%.2f\" % accuracy, \"%.2f\" % recall, \"%.2f\" % precision, sep='\\t')\n",
    "    #print('=' * 10 + str(rem) + '='* 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abundance analysis (Finally!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ORA with abundance cutoffs\n",
    "#nums_removed_metabolites = [0, 25, 50, 75]\n",
    "PVAL_CUTOFF = 0.05\n",
    "#fh = open('/home/zxu/Documents/github_local/ora-msc/data/' + 'abundance.tsv', 'a')\n",
    "fh = open('./data/' + 'abundance.tsv', 'w')\n",
    "\n",
    "fh.write('\\t'.join(['# removed', 'tp', 'fp', 'tn', 'fn', 'nonsig', 'lowmet', 'tested', 'de', 'accu', 'recall', 'precision']))\n",
    "fh.write('\\n')\n",
    "fh.write('# P-val cutoff: ')\n",
    "fh.write(str(PVAL_CUTOFF) + '\\n')\n",
    "\n",
    "for k in range(0, 500):\n",
    "    de_metabolites = simulateDEmet(dataset_paths, 2, pathway_2_compounds, background_met)\n",
    "    (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(set(de_metabolites), hsa_pathways, background_met,\n",
    "                                                               pathway_2_compounds, True, False, 0, [])\n",
    "    correct_pathway_hits = set()\n",
    "    for path in dict(zip(path_ids, path_pvals)):\n",
    "        if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "            correct_pathway_hits.add(path)\n",
    "    # If no significant pathways, run again\n",
    "    # (Seems it does not work the way I wanted)\n",
    "    if len(correct_pathway_hits) == 0:\n",
    "        k -= 1\n",
    "        continue\n",
    "        \n",
    "    all_tested_paths = set(path_ids) # Store for the calculation of negatives\n",
    "    \n",
    "    fh.write('# DE metabolites: ')\n",
    "    fh.write(','.join(list(de_metabolites)))\n",
    "    fh.write('\\n')\n",
    "    fh.write('# Significant pathways: ')\n",
    "    fh.write(str(len(correct_pathway_hits)) + '\\n')\n",
    "\n",
    "    for rem in range(0, 100, 10):\n",
    "        new_de_mets = set()\n",
    "        new_background = set()\n",
    "        removed_mets = []\n",
    "        new_pathway_hits = set()\n",
    "        new_pathway_nonsig = set()\n",
    "        new_pathway_negs = set()\n",
    "        # Select removed metabolites and remove them from DE and background\n",
    "        for item in sorted_met[:rem]:\n",
    "            metabolite = item[0]\n",
    "            removed_mets.append(metabolite)\n",
    "        for metabolite in de_metabolites:\n",
    "            if metabolite not in removed_mets:\n",
    "                new_de_mets.add(metabolite)\n",
    "        for metabolite in background_met:\n",
    "            if metabolite not in removed_mets:\n",
    "                new_background.add(metabolite)\n",
    "        # ORA\n",
    "        (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(new_de_mets, hsa_pathways, new_background,\n",
    "                                                                   pathway_2_compounds, True, False, 0, [])\n",
    "        #if len(path_ids) == 0:\n",
    "        #    pass\n",
    "        # Report results\n",
    "        for path in dict(zip(path_ids, path_pvals)):\n",
    "            if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "                new_pathway_hits.add(path)\n",
    "            else:\n",
    "                new_pathway_nonsig.add(path)\n",
    "                \n",
    "        new_pathway_negs = all_tested_paths.difference(new_pathway_hits)\n",
    "                \n",
    "        tp = len(correct_pathway_hits & new_pathway_hits)\n",
    "        fp = len(new_pathway_hits.difference(correct_pathway_hits))\n",
    "        fn = len(new_pathway_negs & correct_pathway_hits)\n",
    "        tn = len(new_pathway_negs.difference(correct_pathway_hits))\n",
    "        fn_nonsig = len(new_pathway_nonsig & correct_pathway_hits)\n",
    "        fn_lowmet = fn - fn_nonsig\n",
    "        accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "        recall = tp / (tp + fn)\n",
    "        try:\n",
    "            precision = tp /(tp + fp)\n",
    "        except ZeroDivisionError:\n",
    "            precision = np.NaN\n",
    "        #print(len(path_ids))\n",
    "        #'\\t'.join(list(map(str, [rem, tp, fp, tn, fn])))\n",
    "        fh.write('\\t'.join(list(map(str, [rem, tp, fp, tn, fn, fn_nonsig, fn_lowmet, len(path_ids), len(new_de_mets),\n",
    "                                          \"%.2f\" % accuracy, \"%.2f\" % recall, \"%.2f\" % precision]))))\n",
    "        fh.write('\\n')\n",
    "        #print('=' * 10 + str(rem) + '='* 10)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ORA with abundance cutoffs\n",
    "#nums_removed_metabolites = [0, 25, 50, 75]\n",
    "PVAL_CUTOFF = 0.05\n",
    "#fh = open('/home/zxu/Documents/github_local/ora-msc/data/' + 'shrink.tsv', 'a')\n",
    "fh = open('./data/' + 'shrink_add.tsv', 'w')\n",
    "\n",
    "fh.write('\\t'.join(['# removed', 'tp', 'fp', 'tn', 'fn', 'nonsig', 'lowmet', 'tested', 'de', 'accu', 'recall', 'jaccard']))\n",
    "fh.write('\\n')\n",
    "fh.write('# P-val cutoff: ')\n",
    "fh.write(str(PVAL_CUTOFF) + '\\n')\n",
    "\n",
    "\n",
    "for k in range(0, 2):\n",
    "    print(k)\n",
    "    de_metabolites = simulateDEmet(dataset_paths, 2, pathway_2_compounds, background_met)\n",
    "    (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(set(de_metabolites), hsa_pathways, background_met,\n",
    "                                                               pathway_2_compounds, True, False, 0, [])\n",
    "    correct_pathway_hits = set()\n",
    "    for path in dict(zip(path_ids, path_pvals)):\n",
    "        if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "            correct_pathway_hits.add(path)\n",
    "    # If no significant pathways, run again\n",
    "    if len(correct_pathway_hits) == 0:\n",
    "        k -= 1\n",
    "        continue\n",
    "    \n",
    "    all_tested_paths = set(path_ids) # Store for the calculation of negatives\n",
    "    \n",
    "    fh.write('# DE metabolites: ')\n",
    "    fh.write(','.join(list(de_metabolites)))\n",
    "    fh.write('\\n')\n",
    "    fh.write('# Significant pathways: ')\n",
    "    fh.write(str(len(correct_pathway_hits)) + '\\n')\n",
    "\n",
    "    for i in range(0, 50):\n",
    "    \n",
    "        # Shuffle background met so they can be randomly removed\n",
    "        metlist = list(background_met)\n",
    "        random.shuffle(metlist)\n",
    "        \n",
    "        for rem in range(0, 100, 10):\n",
    "            new_de_mets = set()\n",
    "            new_background = set()\n",
    "            removed_mets = []\n",
    "            new_pathway_hits = set()\n",
    "            new_pathway_nonsig = set()\n",
    "            new_pathway_negs = set()\n",
    "            # Select removed metabolites and remove them from DE and background\n",
    "            for metabolite in metlist[:rem]:\n",
    "                removed_mets.append(metabolite)\n",
    "            for metabolite in de_metabolites:\n",
    "                if metabolite not in removed_mets:\n",
    "                    new_de_mets.add(metabolite)\n",
    "            for metabolite in background_met:\n",
    "                if metabolite not in removed_mets:\n",
    "                    new_background.add(metabolite)\n",
    "            # Calculate average jaccard coefficient        \n",
    "            new_p2c = dict()\n",
    "            for pathway in dataset_paths:\n",
    "                detectable_metabolite = pathway_2_compounds[pathway] & new_background\n",
    "                if len(detectable_metabolite) == 0:\n",
    "                    continue\n",
    "                new_p2c[pathway] = detectable_metabolite\n",
    "            jcd_coeff = (mean_jaccard_coeff(new_p2c.values()))\n",
    "            # ORA\n",
    "            (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(new_de_mets, hsa_pathways, new_background,\n",
    "                                                                       pathway_2_compounds, True, False, 0, [])\n",
    "            if len(path_ids) == 0:\n",
    "                pass\n",
    "            # Report results\n",
    "            for path in dict(zip(path_ids, path_pvals)):\n",
    "                if dict(zip(path_ids, path_pvals))[path] < PVAL_CUTOFF:\n",
    "                    new_pathway_hits.add(path)\n",
    "                else:\n",
    "                    new_pathway_nonsig.add(path)\n",
    "\n",
    "            new_pathway_negs = all_tested_paths.difference(new_pathway_hits)\n",
    "                \n",
    "            tp = len(correct_pathway_hits & new_pathway_hits)\n",
    "            fp = len(new_pathway_hits.difference(correct_pathway_hits))\n",
    "            fn = len(new_pathway_negs & correct_pathway_hits)\n",
    "            tn = len(new_pathway_negs.difference(correct_pathway_hits))\n",
    "            fn_nonsig = len(new_pathway_nonsig & correct_pathway_hits)\n",
    "            fn_lowmet = fn - fn_nonsig\n",
    "            accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "            recall = tp / (tp + fn)\n",
    "            try:\n",
    "                precision = tp /(tp + fp)\n",
    "            except ZeroDivisionError:\n",
    "                precision = np.NaN\n",
    "        \n",
    "            #print(len(path_ids))\n",
    "            #'\\t'.join(list(map(str, [rem, tp, fp, tn, fn])))\n",
    "            fh.write('\\t'.join(list(map(str, [rem, tp, fp, tn, fn, fn_nonsig, fn_lowmet, len(path_ids), len(new_de_mets),\n",
    "                                              \"%.2f\" % accuracy, \"%.2f\" % recall, jcd_coeff]))))\n",
    "            fh.write('\\n')\n",
    "            #print('=' * 10 + str(rem) + '='* 10)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null models (Liver dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsa_cmpds = list(ora_msc.get_all_compounds('hsa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{'C00187', C17714, C16834, 'C00219', C00334}\n",
    "for k in range(0, 10):\n",
    "    null_model = ora_msc.make_null_model(pathway_2_compounds, hsa_cmpds, True)\n",
    "    (path_pvals, path_ids, path_sizes) = ora_msc.oras_allpaths(set(de_metabolites), hsa_pathways, set(background_met),\n",
    "                                                               null_model, True, False, 0, [])\n",
    "    for path in dict(zip(path_ids, path_pvals)):\n",
    "        if dict(zip(path_ids, path_pvals))[path] < 0.05:\n",
    "            print(path, dict(zip(path_ids, path_pvals))[path])\n",
    "            print(null_model[path] & background_met)\n",
    "    print(path_sizes)\n",
    "    print('=' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger background with less de_size = worse fpr\n",
    "- Min num of pathway size should be adjusted according to these two values\n",
    "- When bg = 100, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATHWAY_COMPOUND_SIZE = 2\n",
    "PATHWAY_DE_METABOLITES = 1\n",
    "BACKGROUND_SIZE = 108\n",
    "DE_MET_SIZE = 5\n",
    "\n",
    "for DE_MET_SIZE in range(5, 6):\n",
    "    hyperg_test = hypergeom(BACKGROUND_SIZE, PATHWAY_COMPOUND_SIZE, DE_MET_SIZE)\n",
    "    ora_raw_pval = 1 - hyperg_test.cdf(PATHWAY_DE_METABOLITES) + hyperg_test.pmf(PATHWAY_DE_METABOLITES)\n",
    "    print(ora_raw_pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing abundance & random results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dict(in_dict):\n",
    "    xvals = []\n",
    "    yvals = []\n",
    "    sorted_keys = sorted(list(in_dict.keys()))[::-1]\n",
    "    for key in sorted_keys:\n",
    "        xvals.append(key)\n",
    "        yvals.append(in_dict[key])\n",
    "    print(xvals)\n",
    "    print(yvals)\n",
    "    plt.plot(xvals, yvals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#abun_results = '/home/zxu/Documents/github_local/ora-msc/data/' + 'abundance.tsv'\n",
    "#shrink_results = '/home/zxu/Documents/github_local/ora-msc/data/' + 'shrink.tsv'\n",
    "shrink_results = './data/' + 'shrink_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "de_simcount = 0\n",
    "de_mets_vs_sigpaths = dict()\n",
    "with open(shrink_results, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    for line in lines[2:]:\n",
    "        if line.startswith('# DE'):\n",
    "            de_mets = line.rstrip().split(': ')[1]\n",
    "            de_mets = de_mets.split(',')\n",
    "        elif line.startswith('# Sig'):\n",
    "            sigpaths = int(line.rstrip().split(': ')[1])\n",
    "            de_simcount += 1\n",
    "            try:\n",
    "                de_mets_vs_sigpaths[len(de_mets)].append(sigpaths)\n",
    "            except KeyError:\n",
    "                de_mets_vs_sigpaths[len(de_mets)] = [sigpaths]\n",
    "for key in de_mets_vs_sigpaths:\n",
    "    de_mets_vs_sigpaths[key] = np.mean(de_mets_vs_sigpaths[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "de_simcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_dict(de_mets_vs_sigpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accu_vs_remove = dict()\n",
    "recall_vs_remove = dict()\n",
    "with open(shrink_results, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    for line in lines:\n",
    "        if not line.startswith('#'):\n",
    "            fields = line.rstrip().split('\\t')\n",
    "            removed = fields[0]\n",
    "            accu = float(fields[9])\n",
    "            recall = float(fields[10])\n",
    "            try:\n",
    "                accu_vs_remove[removed].append(accu)\n",
    "            except KeyError:\n",
    "                accu_vs_remove[removed] = [accu]\n",
    "            try:\n",
    "                recall_vs_remove[removed].append(recall)\n",
    "            except KeyError:\n",
    "                recall_vs_remove[removed] = [recall]\n",
    "for key in accu_vs_remove:\n",
    "    accu_vs_remove[key] = np.mean(accu_vs_remove[key])\n",
    "for key in recall_vs_remove:\n",
    "    recall_vs_remove[key] = np.mean(recall_vs_remove[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accu_vs_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['90', '80', '70', '60', '50', '40', '30', '20', '10', '0']\n",
      "[0.22929408742645097, 0.16510690572995601, 0.13163344353561399, 0.10878450019942801, 0.097157186730319992, 0.087516459917420006, 0.079352738461711994, 0.073822959290174003, 0.068803217395293992, 0.065572248412300013]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_dict(recall_vs_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_fp = 0\n",
    "last_de = 100\n",
    "increased_fp = []\n",
    "decreased_de = []\n",
    "with open(shrink_results, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    for line in lines:\n",
    "        if not line.startswith('#'):\n",
    "            fields = line.rstrip().split('\\t')\n",
    "            fp = int(fields[2])\n",
    "            de = int(fields[8])\n",
    "            if fp > last_fp and de < last_de:\n",
    "                increased_fp.append(1)\n",
    "                decreased_de.append(1)\n",
    "            elif fp > last_fp and de == last_de:\n",
    "                increased_fp.append(0)\n",
    "            elif de < last_de:\n",
    "                decreased_de.append(0)\n",
    "            last_fp = fp\n",
    "            last_de = de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.sum(increased_fp))\n",
    "print(np.sum(decreased_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(increased_fp))\n",
    "print(len(decreased_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecoli_compounds = ora_msc.get_all_compounds('eco')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
